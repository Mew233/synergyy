{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ada1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chengqi_xu/.conda/envs/synergyy/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from torch.utils.data import DataLoader\n",
    "from itertools import chain\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd48ee",
   "metadata": {},
   "source": [
    "#### select 4298 genes (top varaince as well as drug-targeted genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f64e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_exp = pd.read_csv(\"/Users/chengqi_xu/Documents/Elemento lab/synergyy/data/cell_line_data/tcga/tcga_exp.csv\").T\n",
    "ccle_exp = pd.read_csv(\"/Users/chengqi_xu/Documents/Elemento lab/synergyy/data/cell_line_data/tcga/CCLE_exp.csv\",index_col=0)\n",
    "final_table_columns = ccle_exp.index\n",
    "df = tcga_exp.drop(columns=[col for col in tcga_exp if col not in final_table_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22050b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12236, 4298)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3925d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = Variable(torch.Tensor(np.array(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270462c6",
   "metadata": {},
   "source": [
    "#### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1ae453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int, latent_dim: int, hidden_dims: list = None, \\\n",
    "        dop: float = 0.1, noise_flag: bool = False, **kwargs) -> None:\n",
    "        super(AE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.noise_flag = noise_flag\n",
    "        self.dop = dop\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [512]\n",
    "\n",
    "        # build encoder\n",
    "        modules = []\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dims[0], bias=True),\n",
    "                #nn.BatchNorm1d(hidden_dims[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dop)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dims[i], hidden_dims[i + 1], bias=True),\n",
    "                    #nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(self.dop)\n",
    "                )\n",
    "            )\n",
    "        modules.append(nn.Dropout(self.dop))\n",
    "        modules.append(nn.Linear(hidden_dims[-1], latent_dim, bias=True))\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        # build decoder\n",
    "        modules = []\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(latent_dim, hidden_dims[-1], bias=True),\n",
    "                #nn.BatchNorm1d(hidden_dims[-1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dop)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dims[i], hidden_dims[i + 1], bias=True),\n",
    "                    #nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(self.dop)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1], hidden_dims[-1], bias=True),\n",
    "            #nn.BatchNorm1d(hidden_dims[-1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dop),\n",
    "            nn.Linear(hidden_dims[-1], input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        encoded_input = self.encoder(input)\n",
    "        encoded_input = nn.functional.normalize(encoded_input, p=2, dim=1)\n",
    "        output = self.final_layer(self.decoder(encoded_input))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def encode(self, input):\n",
    "        return self.encoder(input)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7860a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = dataX.shape[1]\n",
    "latent_dim = 256\n",
    "model = AE(input_size,latent_dim)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65c8ddf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/50], loss:15.8928\n",
      "epoch [2/50], loss:3.6415\n",
      "epoch [3/50], loss:2.1240\n",
      "epoch [4/50], loss:1.9584\n",
      "epoch [5/50], loss:1.9074\n",
      "epoch [6/50], loss:1.8823\n",
      "epoch [7/50], loss:1.9394\n",
      "epoch [8/50], loss:1.9135\n",
      "epoch [9/50], loss:1.8398\n",
      "epoch [10/50], loss:1.8488\n",
      "epoch [11/50], loss:1.6355\n",
      "epoch [12/50], loss:1.6457\n",
      "epoch [13/50], loss:1.5972\n",
      "epoch [14/50], loss:1.6502\n",
      "epoch [15/50], loss:1.5408\n",
      "epoch [16/50], loss:1.5821\n",
      "epoch [17/50], loss:1.4096\n",
      "epoch [18/50], loss:1.3687\n",
      "epoch [19/50], loss:1.3725\n",
      "epoch [20/50], loss:1.3456\n",
      "epoch [21/50], loss:1.3521\n",
      "epoch [22/50], loss:1.3278\n",
      "epoch [23/50], loss:1.3181\n",
      "epoch [24/50], loss:1.2667\n",
      "epoch [25/50], loss:1.2560\n",
      "epoch [26/50], loss:1.2458\n",
      "epoch [27/50], loss:1.2618\n",
      "epoch [28/50], loss:1.2014\n",
      "epoch [29/50], loss:1.2224\n",
      "epoch [30/50], loss:1.1992\n",
      "epoch [31/50], loss:1.1930\n",
      "epoch [32/50], loss:1.2392\n",
      "epoch [33/50], loss:1.1625\n",
      "epoch [34/50], loss:1.1621\n",
      "epoch [35/50], loss:1.1419\n",
      "epoch [36/50], loss:1.1283\n",
      "epoch [37/50], loss:1.0926\n",
      "epoch [38/50], loss:1.0981\n",
      "epoch [39/50], loss:1.1047\n",
      "epoch [40/50], loss:1.0825\n",
      "epoch [41/50], loss:1.1073\n",
      "epoch [42/50], loss:1.0732\n",
      "epoch [43/50], loss:1.0653\n",
      "epoch [44/50], loss:1.0302\n",
      "epoch [45/50], loss:1.0325\n",
      "epoch [46/50], loss:1.0247\n",
      "epoch [47/50], loss:1.0401\n",
      "epoch [48/50], loss:0.9992\n",
      "epoch [49/50], loss:1.0117\n",
      "epoch [50/50], loss:0.9504\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataX, batch_size=256,shuffle=True)\n",
    "\n",
    "num_epochs = 50\n",
    "# do = nn.Dropout()  # comment out for standard AE\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img = data\n",
    "        # ===================forward=====================\n",
    "        output = model(img)  # feed  (for std AE) or  (for denoising AE)\n",
    "        loss = criterion(output, img.data)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], loss:{loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e94d618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROOT_DIR = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "#save_path = os.path.join(ROOT_DIR, 'data','cell_line_data','tcga_encoder.pth')\n",
    "torch.save(model.state_dict(), \"/Users/chengqi_xu/Documents/Elemento lab/synergyy/data/cell_line_data/tcga/tcga_encoder.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('synergyy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c961a5698cf0a06e44a9b39867173e70e7f5b41ad5fe4e792827527847a8f1b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
